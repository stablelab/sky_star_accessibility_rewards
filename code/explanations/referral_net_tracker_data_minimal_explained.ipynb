{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referral Net Tracker - Data Gathering\n",
    "\n",
    "This notebook explains the data gathering steps of the referral net tracker algorithm. The algorithm tracks referral funds in the Sky/Star Accessibility Rewards system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, we import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join, dirname\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set reward percentage and initial check date\n",
    "reward_percentage = 0.4/100\n",
    "checkFrom = datetime.datetime.fromisoformat('2030-12-20 23:59:59')\n",
    "\n",
    "# Set up path and environment variables\n",
    "base = os.path.abspath(\"\")\n",
    "import sys\n",
    "## add your path to the code folder from your jupyter server root directry below.\n",
    "# if you use local running ipython in vscode no path adaptions are neccessary\n",
    "sys.path.append(os.path.join(base,'../sky_star_acessibility_rewards/code')) \n",
    "\n",
    "# Load environment variables\n",
    "dotenv_path = join(dirname(os.path.dirname('__file__')), '.env')\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(base,'../sky_star_acessibility_rewards/code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database Connection Setup\n",
    "\n",
    "We connect to both Snowflake and PostgreSQL databases to fetch and store data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Import configuration settings from config file\n",
    "from common.config import (\n",
    "    DATABASE_NAME,\n",
    "    DATABASE_HOST,\n",
    "    DATABASE_USER,\n",
    "    DATABASE_PASSWORD,\n",
    "    DATABASE_PORT,\n",
    "    SNOWFLAKE_ACCOUNT,\n",
    "    SNOWFLAKE_USER,\n",
    "    SNOWFLAKE_PASSWORD,\n",
    "    SNOWFLAKE_DATABASE\n",
    ")\n",
    "\n",
    "# Import custom modules for decoding\n",
    "import common.stablelib.action_decoder.referral_fund_tracker_decode as rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute the script you need access to a flipside snowflake equivalent, easiest to be found here: https://docs.flipsidecrypto.xyz/welcome-to-flipside/data/choose-your-flipside-plan/pro\n",
    "\n",
    "In general the events table needs to have the following columns:\n",
    "| Column | Description |\n",
    "|--------|-------------|\n",
    "| block_timestamp | When the event occurred |\n",
    "| block_number | Block number of the event |\n",
    "| tx_hash | Transaction hash |\n",
    "| event_name | Type of event (e.g., transfer, deposit, withdraw) |\n",
    "| dl | Decoded log data containing event-specific information |\n",
    "| contract_address | Contract address |\n",
    "| event_index | Order of event in transaction |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Database Connections\n",
    "\n",
    "Establish connections to Snowflake and PostgreSQL databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Snowflake\n",
    "snowflake_conn = snowflake.connector.connect(\n",
    "    user=SNOWFLAKE_USER,\n",
    "    password=SNOWFLAKE_PASSWORD,\n",
    "    account=SNOWFLAKE_ACCOUNT,\n",
    "    database=SNOWFLAKE_DATABASE,\n",
    ")\n",
    "\n",
    "# Connect to PostgreSQL\n",
    "connection = \"postgresql://\"+DATABASE_USER+\":\"+DATABASE_PASSWORD+\"@\"+DATABASE_HOST+\":\"+DATABASE_PORT+\"/\"+DATABASE_NAME\n",
    "engine = create_engine(connection) \n",
    "\n",
    "# Get sUSDS prices for later calculations\n",
    "query_sUSDSprices=\"\"\"SELECT DISTINCT ON (DATE_TRUNC('month', date)) token_id, date, price\n",
    "FROM coingecko.market_data\n",
    "where token_id = 'susds'\n",
    "ORDER BY DATE_TRUNC('month', date) DESC, date DESC\n",
    "\"\"\"\n",
    "dfsUSDSPrices = pd.read_sql(query_sUSDSprices, engine)\n",
    "dfsUSDSPrices['month'] = dfsUSDSPrices['date'].dt.to_period('M')\n",
    "print('Got sUSDS prices')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Gathering - sUSDS Logs\n",
    "\n",
    "First, we fetch logs from the sUSDS contract to track transfers and other events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tracking time for performance measurement\n",
    "all_timer = time.time()\n",
    "timer = time.time()\n",
    "\n",
    "print(\"Starting data gathering\")\n",
    "print(\"Date:\", datetime.datetime.now())\n",
    "\n",
    "# Query to fetch sUSDS logs\n",
    "susds_logs = \"\"\"\n",
    "    SELECT * FROM ethereum.core.ez_decoded_event_logs WHERE contract_address = lower('0xa3931d71877C0E7a3148CB7Eb4463524FEc27fbD') AND tx_status = 'SUCCESS'\n",
    "\"\"\"\n",
    "dfSUsdsLogs = pd.read_sql(susds_logs, snowflake_conn)\n",
    "\n",
    "# Process the data\n",
    "dfSUsdsLogs.columns = dfSUsdsLogs.columns.str.lower()\n",
    "dfSUsdsLogs['dl'] = dfSUsdsLogs['decoded_log'].apply(lambda x: json.loads(x))\n",
    "dfSUsdsLogs = dfSUsdsLogs[[\n",
    "    'block_timestamp', 'block_number', 'tx_hash',\n",
    "    'event_name', 'dl', 'contract_address', 'contract_name', 'event_index', 'origin_function_signature', 'origin_from_address',\n",
    "    'origin_to_address', 'topics'\n",
    "]]\n",
    "\n",
    "print(f\"USDS data loaded: {time.time()-timer:.2f} seconds, {dfSUsdsLogs.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Gathering - Cowswap Logs\n",
    "\n",
    "Next, we fetch Cowswap-related events and create synthetic referrals based on deposit/stake events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = time.time()\n",
    "\n",
    "# Query to fetch Cowswap logs\n",
    "cowswap_logs_query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM ethereum.core.ez_decoded_event_logs AS del\n",
    "    WHERE EXISTS (\n",
    "        SELECT 1\n",
    "        FROM ethereum.core.ez_decoded_event_logs AS del1\n",
    "        WHERE del1.tx_hash = del.tx_hash\n",
    "        AND del1.contract_address = LOWER('0x9008d19f58aabd9ed0d60971565aa8510560ab41')\n",
    "    )\n",
    "    AND EXISTS (\n",
    "        SELECT 1\n",
    "        FROM ethereum.core.ez_decoded_event_logs AS del2\n",
    "        WHERE del2.tx_hash = del.tx_hash\n",
    "        AND del2.contract_address IN (\n",
    "            LOWER('0xa3931d71877C0E7a3148CB7Eb4463524FEc27fbD'),\n",
    "            LOWER('0x0650CAF159C5A49f711e8169D4336ECB9b950275'),\n",
    "            LOWER('0x10ab606B067C9C461d8893c47C7512472E19e2Ce')\n",
    "        )\n",
    "        AND del2.tx_status = 'SUCCESS'\n",
    "    )\n",
    "\"\"\"\n",
    "cowswap_logs = pd.read_sql(cowswap_logs_query, snowflake_conn)\n",
    "cowswap_logs.columns = cowswap_logs.columns.str.lower()\n",
    "\n",
    "# Filter for deposit/staked events on relevant contracts\n",
    "deposit_staked_df = cowswap_logs[(cowswap_logs['event_name'] == 'Deposit') | (cowswap_logs['event_name'] == 'Staked')]\n",
    "deposit_staked_df = deposit_staked_df[deposit_staked_df['contract_address'].isin([\n",
    "    '0xa3931d71877c0e7a3148cb7eb4463524fec27fbd',\n",
    "    '0x0650caf159c5a49f711e8169d4336ecb9b950275',\n",
    "    '0x10ab606b067c9c461d8893c47c7512472e19e2ce'\n",
    "])]\n",
    "\n",
    "# Create synthetic referrals for Cowswap (referral code 1003)\n",
    "synthetic_referals = deposit_staked_df.copy()[0:0]\n",
    "for index, row in deposit_staked_df.iterrows():\n",
    "    if row['event_name'] == 'Deposit':\n",
    "        referral = row.copy()\n",
    "        tjson = json.loads(row['decoded_log'])\n",
    "        tjson['referral'] = 1003  # Cowswap referral code\n",
    "        referral['event_name'] = 'Referral'\n",
    "        referral['decoded_log'] = json.dumps(tjson)\n",
    "        synthetic_referals = synthetic_referals._append(referral)\n",
    "    if row['event_name'] == 'Staked':\n",
    "        staked = row.copy()\n",
    "        amount = json.loads(row['decoded_log'])['amount']\n",
    "        user = json.loads(row['decoded_log'])['user']\n",
    "        staked['decoded_log'] = '{\"amount\": \"' + amount + '\", \"referral\": 1003, \"user\": \"' + user + '\"}'\n",
    "        synthetic_referals = synthetic_referals._append(staked)\n",
    "\n",
    "# Process the synthetic data\n",
    "synthetic_referals['dl'] = synthetic_referals['decoded_log'].apply(lambda x: json.loads(x))\n",
    "synthetic_referals = synthetic_referals[[\n",
    "    'block_timestamp','block_number', 'tx_hash',\n",
    "    'event_name', 'dl','contract_address', 'contract_name','event_index', 'origin_function_signature', 'origin_from_address',\n",
    "    'origin_to_address', 'topics'\n",
    "]]\n",
    "synthetic_referals['event_name'] = synthetic_referals['event_name'].str.lower()\n",
    "\n",
    "print(f\"Cowswap data loaded: {time.time()-timer:.2f} seconds, {synthetic_referals.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Gathering - LazySummer Logs\n",
    "\n",
    "We also fetch LazySummer-related events and create synthetic referrals (referral code 1016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = time.time()\n",
    "\n",
    "# Query to fetch LazySummer logs\n",
    "lazysummer_logs_query = \"\"\"\n",
    "    SELECT * FROM ethereum.core.ez_decoded_event_logs\n",
    "    WHERE tx_hash IN (\n",
    "        SELECT d.tx_hash\n",
    "        FROM ethereum.core.ez_decoded_event_logs d\n",
    "        WHERE d.contract_address IN ('0xa3931d71877c0e7a3148cb7eb4463524fec27fbd', '0x0650caf159c5a49f711e8169d4336ecb9b950275', '0x10ab606b067c9c461d8893c47c7512472e19e2ce')\n",
    "        AND d.event_name = 'Deposit'\n",
    "        AND EXISTS (\n",
    "            -- Check if the same transaction has a \"Rebalanced\" event (from any contract)\n",
    "            SELECT 1\n",
    "            FROM ethereum.core.ez_decoded_event_logs r\n",
    "            WHERE r.tx_hash = d.tx_hash\n",
    "            AND r.event_name = 'Rebalanced'\n",
    "        )\n",
    "    )\n",
    "\"\"\"\n",
    "lazysummer_logs_query = pd.read_sql(lazysummer_logs_query, snowflake_conn)\n",
    "print(\"lazysummer_logs_query done\")\n",
    "\n",
    "# Process the data\n",
    "lazysummer_logs_query.columns = lazysummer_logs_query.columns.str.lower()\n",
    "\n",
    "# Filter deposit/staked events for relevant contracts\n",
    "deposit_staked_df = lazysummer_logs_query[(lazysummer_logs_query['event_name'] == 'Deposit') | (lazysummer_logs_query['event_name'] == 'Staked')]\n",
    "deposit_staked_df = deposit_staked_df[deposit_staked_df['contract_address'].isin([\n",
    "    '0xa3931d71877c0e7a3148cb7eb4463524fec27fbd',\n",
    "    '0x0650caf159c5a49f711e8169d4336ecb9b950275',\n",
    "    '0x10ab606b067c9c461d8893c47c7512472e19e2ce'\n",
    "])]\n",
    "\n",
    "# Create synthetic referrals for LazySummer (referral code 1016)\n",
    "synthetic_referals_lazysummer = deposit_staked_df.copy()[0:0]\n",
    "for index, row in deposit_staked_df.iterrows():\n",
    "    if row['event_name'] == 'Deposit':\n",
    "        referral = row.copy()\n",
    "        amount = json.loads(row['decoded_log'])['shares']\n",
    "        user = json.loads(row['decoded_log'])['owner']\n",
    "        referral['event_name'] = 'Referral'\n",
    "        referral['decoded_log'] = '{\"amount\": \"' + amount + '\", \"referral\": 1016, \"user\": \"' + user + '\"}'\n",
    "        synthetic_referals_lazysummer = synthetic_referals_lazysummer._append(referral)\n",
    "    if row['event_name'] == 'Staked':\n",
    "        staked = row.copy()\n",
    "        amount = json.loads(row['decoded_log'])['amount']\n",
    "        user = json.loads(row['decoded_log'])['user']\n",
    "        referral['decoded_log'] = '{\"amount\": \"' + amount + '\", \"referral\": 1016, \"user\": \"' + user + '\"}'\n",
    "        synthetic_referals_lazysummer = synthetic_referals_lazysummer._append(staked)\n",
    "\n",
    "# Process the synthetic LazySummer data\n",
    "synthetic_referals_lazysummer['dl'] = synthetic_referals_lazysummer['decoded_log'].apply(lambda x: json.loads(x))\n",
    "synthetic_referals_lazysummer = synthetic_referals_lazysummer[[\n",
    "    'block_number','block_timestamp', 'tx_hash',\n",
    "    'event_name', 'dl','contract_address', 'contract_name','event_index', 'origin_function_signature', 'origin_from_address',\n",
    "    'origin_to_address', 'topics'\n",
    "]]\n",
    "synthetic_referals_lazysummer['event_name'] = synthetic_referals_lazysummer['event_name'].str.lower()\n",
    "\n",
    "# Combine all synthetic referrals\n",
    "synthetic_referals = pd.concat([synthetic_referals, synthetic_referals_lazysummer])\n",
    "\n",
    "# Display statistics about the synthetic data\n",
    "referral_codes = synthetic_referals['dl'].apply(lambda x: x['referral'] if isinstance(x,dict) and 'referral' in x else 'broken').value_counts()\n",
    "print(f\"Synthetic LazySummer data loaded: {time.time()-timer:.2f} seconds, {synthetic_referals.shape[0]} rows\")\n",
    "display(referral_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Gathering - SkyFarm Logs\n",
    "\n",
    "Finally, we fetch events from the SkyFarm contracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer = time.time()\n",
    "\n",
    "# Define the contract addresses we're interested in\n",
    "contracts = [\n",
    "    '0x0650caf159c5a49f711e8169d4336ecb9b950275',  # Sky Farm\n",
    "    '0x10ab606B067C9C461d8893c47C7512472E19e2Ce',  # Chronicle \n",
    "    '0xa3931d71877C0E7a3148CB7Eb4463524FEc27fbD'   # sUSDS Farm\n",
    "]\n",
    "print(\"Analyzing contracts:\", contracts)\n",
    "\n",
    "# Ensure all contract addresses are lowercase\n",
    "contracts = [x.lower() for x in contracts]\n",
    "\n",
    "# Query to fetch all events from the specified contracts\n",
    "sky_farm_logs_all = \"\"\"\n",
    "    SELECT * FROM ethereum.core.ez_decoded_event_logs WHERE contract_address IN (%s)\n",
    "\"\"\" % \",\".join([\"('\" + x.lower() + \"')\" for x in contracts])\n",
    "dfSFLogs = pd.read_sql(sky_farm_logs_all, snowflake_conn)\n",
    "\n",
    "# Process the data\n",
    "dfSFLogs.columns = dfSFLogs.columns.str.lower()\n",
    "dfSFLogs['dl'] = dfSFLogs['decoded_log'].apply(lambda x: json.loads(x))\n",
    "dfSFLogs = dfSFLogs[[\n",
    "    'block_timestamp', 'block_number', 'tx_hash',\n",
    "    'event_name', 'dl', 'contract_address', 'contract_name', 'event_index', 'origin_function_signature', 'origin_from_address',\n",
    "    'origin_to_address', 'topics'\n",
    "]]\n",
    "dfSFLogs['event_name'] = dfSFLogs['event_name'].str.lower()\n",
    "\n",
    "# Get deposits with referral codes\n",
    "dfDeposits = dfSFLogs[(dfSFLogs['event_name'] == 'referral') & (dfSFLogs['contract_address'] == contracts[-1])]\n",
    "\n",
    "print(f\"SkyFarm data loaded: {time.time()-timer:.2f} seconds, {dfSFLogs.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Processing and Consolidation\n",
    "\n",
    "Now we process and combine all the data for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled NAs: 0 -> 0\n",
      "Data loaded and processed: 0.51 seconds, 5073 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2669817/897973127.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfUSDSB['am'] = dfUSDSB.apply(\n",
      "/tmp/ipykernel_2669817/897973127.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfSFStakeWithdraw['am'] = dfSFStakeWithdraw.apply(\n",
      "/tmp/ipykernel_2669817/897973127.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfRelEventsRef.sort_values(['block_timestamp','event_index'], inplace=True, ascending=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "event_name\n",
       "staked       1732\n",
       "transfer     1272\n",
       "deposit       757\n",
       "withdrawn     618\n",
       "referral      349\n",
       "withdraw      345\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timer = time.time()\n",
    "\n",
    "# Ensure consistent event name format\n",
    "dfSFLogs['event_name'] = dfSFLogs['event_name'].str.lower()\n",
    "dfSUsdsLogs['event_name'] = dfSUsdsLogs['event_name'].str.lower()\n",
    "\n",
    "# Fill missing timestamps through interpolation\n",
    "na_count = dfSFLogs['block_timestamp'].isna().sum()\n",
    "dfSFLogs = dfSFLogs.sort_values(by=['block_number','event_index'], ascending=False)\n",
    "dfSFLogs['block_timestamp'] = dfSFLogs['block_timestamp'].interpolate()\n",
    "print(f\"Filled NAs: {na_count} -> {dfSFLogs['block_timestamp'].isna().sum()}\")\n",
    "\n",
    "# Extract transfer events from sUSDS logs\n",
    "dfSUsdsLogsT = dfSUsdsLogs[dfSUsdsLogs['event_name'] == 'transfer']\n",
    "\n",
    "# Process deposit/withdraw events from sUSDS\n",
    "dfUSDSB = dfSFLogs[dfSFLogs['event_name'].isin(['withdrawn','deposit','withdraw']) & \n",
    "                   (dfSFLogs['contract_address'].str.lower() == contracts[-1].lower())]\n",
    "dfUSDSB['am'] = dfUSDSB.apply(\n",
    "    lambda x: int(x['dl']['shares']) if x['event_name'] == 'deposit' else -1*int(x['dl']['shares']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Process stake/withdraw events from SkyFarm\n",
    "dfSFStakeWithdraw = dfSFLogs[dfSFLogs['event_name'].isin(['withdrawn','staked']) & \n",
    "                             (dfSFLogs['contract_address'].str.lower() == contracts[0].lower())]\n",
    "dfSFStakeWithdraw['am'] = dfSFStakeWithdraw.apply(\n",
    "    lambda x: int(x['dl']['amount']) if x['event_name'] == 'staked' else -1*int(x['dl']['amount']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Combine all relevant events\n",
    "dfRelEventsRef = dfSFLogs[dfSFLogs['event_name'].isin(['referral','staked','transfer','deposit','withdrawn','withdraw'])]\n",
    "##TEST###\n",
    "#shorten events\n",
    "dfRelEventsRef.sort_values(['block_timestamp','event_index'], inplace=True, ascending=True)\n",
    "dfRelEventsRef= dfRelEventsRef.iloc[:5000,:]\n",
    "\n",
    "dfTraceEvents = pd.concat([dfRelEventsRef, synthetic_referals[synthetic_referals['block_number']<dfRelEventsRef['block_number'].max()]])\n",
    "dfTraceEvents.sort_values(['block_timestamp','event_index'], inplace=True, ascending=True)\n",
    "dfTraceEvents.reset_index(inplace=True)\n",
    "\n",
    "# Display event statistics\n",
    "event_counts = dfTraceEvents['event_name'].value_counts()\n",
    "print(f\"Data loaded and processed: {time.time()-timer:.2f} seconds, {dfTraceEvents.shape[0]} rows\")\n",
    "display(event_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5073, 13)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTraceEvents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data Gathering Process\n",
    "\n",
    "The data gathering process consists of several key steps:\n",
    "\n",
    "1. **Setup and Configuration**: We import necessary libraries and set up environment variables.\n",
    "\n",
    "2. **Database Connections**: We connect to both Snowflake (for blockchain data) and PostgreSQL (for local storage).\n",
    "\n",
    "3. **sUSDS Logs**: We fetch and process events from the sUSDS contract.\n",
    "\n",
    "4. **Cowswap Logs**: We fetch Cowswap-related events and create synthetic referrals with code 1003.\n",
    "\n",
    "5. **LazySummer Logs**: We fetch LazySummer-related events and create synthetic referrals with code 1016.\n",
    "\n",
    "6. **SkyFarm Logs**: We fetch events from the SkyFarm/Chronicle/sUSDS Farm contracts.\n",
    "\n",
    "7. **Data Processing**: We normalize event names, fill missing timestamps, and combine all the data for analysis.\n",
    "\n",
    "The processed data (dfTraceEvents) contains all the events we need to track referral funds, including:\n",
    "- Native referral events\n",
    "- Staking/deposit events\n",
    "- Withdrawal events\n",
    "- Transfer events\n",
    "- Synthetic referral events from integrators like Cowswap and LazySummer\n",
    "\n",
    "This data serves as the foundation for the fund tracking algorithm that follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup methods for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotNumHolder:\n",
    "    \"\"\"\n",
    "    A class to track and manage pot numbers.\n",
    "    \n",
    "    This class maintains a counter for pot numbers that can be incremented,\n",
    "    retrieved, and set. Used for assigning unique identifiers to pots in the\n",
    "    referral tracking system.\n",
    "\n",
    "    Attributes:\n",
    "        potnum (int): The current pot number counter\n",
    "    \"\"\"\n",
    "    potnum = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a new PotNumHolder with counter set to 0.\"\"\"\n",
    "        self.potnum = 0\n",
    "\n",
    "    def get_potnum(self):\n",
    "        \"\"\"Get the current pot number.\n",
    "        \n",
    "        Returns:\n",
    "            int: The current pot number\n",
    "        \"\"\"\n",
    "        return self.potnum\n",
    "\n",
    "    def set_potnum(self, potnum):\n",
    "        \"\"\"Set the pot number to a specific value.\n",
    "        \n",
    "        Args:\n",
    "            potnum (int): The value to set the pot number to\n",
    "        \"\"\"\n",
    "        self.potnum = potnum\n",
    "    \n",
    "    def increment_potnum(self):\n",
    "        \"\"\"Increment the pot number counter by 1.\"\"\"\n",
    "        self.potnum += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_pot(referral_code,address,amount, tx_hash, contract,liquidity_token,previous_tx_trace=[],previous_pot_trace = [], spawn = None, pot_num:PotNumHolder=None):\n",
    "    \"\"\"\n",
    "    Creates a new pot dictionary to track referral and liquidity information.\n",
    "\n",
    "    Args:\n",
    "        referral_code (str): The referral code associated with this pot\n",
    "        address (str): The wallet address that owns this pot\n",
    "        amount (int): The amount of tokens in the pot\n",
    "        tx_hash (str): The transaction hash that created this pot\n",
    "        contract (str): The contract address this pot is associated with\n",
    "        liquidity_token (str): The liquidity token address for this pot\n",
    "        previous_tx_trace (list, optional): List of previous transaction hashes. Defaults to empty list.\n",
    "        previous_pot_trace (list, optional): List of previous pot traces. Defaults to empty list.\n",
    "        spawn (str, optional): Parent pot identifier if this was spawned from another pot. Defaults to None.\n",
    "        pot_num (PotNumHolder, optional): Object to track pot numbering. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new pot dictionary containing all the tracking information\n",
    "    \"\"\"\n",
    "    pot = {\n",
    "        'potnum': pot_num.get_potnum(),\n",
    "        'referral_code': referral_code,\n",
    "        'address': address,\n",
    "        'amount': amount,\n",
    "        'tx_hash': tx_hash,\n",
    "        'spawn': spawn,\n",
    "        'initial_amount': amount,\n",
    "        'contract': contract,\n",
    "        'liquidity_token': liquidity_token,\n",
    "        'TXtrace': previous_tx_trace + [tx_hash],\n",
    "        'POTtrace': previous_pot_trace\n",
    "    }\n",
    "    pot_num.increment_potnum()\n",
    "    return pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pot(from_address, ps, code=None, liquidity_token=None, contract=None):\n",
    "    \"\"\"\n",
    "    Find a matching pot from a list of pots based on various criteria, using FIFO ordering.\n",
    "    \n",
    "    This function is used to locate existing pots when processing transactions and referrals.\n",
    "    It helps track liquidity positions and referral relationships by finding pots that match\n",
    "    the given parameters. The function implements FIFO (First In, First Out) behavior by \n",
    "    returning the first matching pot in the list, assuming pots are stored in chronological order.\n",
    "\n",
    "    Args:\n",
    "        from_address (str): The wallet address to match against pot addresses\n",
    "        ps (list): List of pot dictionaries to search through, ordered by creation time (oldest first)\n",
    "        code (str, optional): Referral code to match. If None, matches any code. Defaults to None.\n",
    "        liquidity_token (str, optional): Token address to match. If None, matches any token. Defaults to None.\n",
    "        contract (str, optional): Contract address to match. If None, matches any contract. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        dict: First matching pot dictionary if found (FIFO order), None otherwise\n",
    "    \"\"\"\n",
    "    for p in ps:  # Iterates in order, implementing FIFO behavior\n",
    "        if (\n",
    "            p['address'] == from_address \n",
    "            and (code == None or p['referral_code'] == code) \n",
    "            and p['amount'] > 0 \n",
    "            and (liquidity_token == p['liquidity_token'] or liquidity_token == None)\n",
    "            and ( contract == None or contract == p['contract'] )\n",
    "        ):\n",
    "            return p\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_log(tx,timestamp,pot_id, integrator,pool,from_address,amount_delta, action, log_list=[]):\n",
    "    \"\"\"\n",
    "    Creates a log entry for tracking pot-related events.\n",
    "\n",
    "    Args:\n",
    "        tx (str): Transaction hash\n",
    "        timestamp (datetime): Timestamp of the event\n",
    "        pot_id (str): Unique identifier for the pot\n",
    "        integrator (str): Name/address of the integrator\n",
    "        pool (str): Pool identifier\n",
    "        from_address (str): Source wallet address\n",
    "        amount_delta (int): Change in amount (positive for additions, negative for removals)\n",
    "        action (str): Type of action performed (e.g. 'stake', 'withdraw')\n",
    "\n",
    "    Returns:\n",
    "        dict: Log entry containing all provided information\n",
    "    \"\"\"\n",
    "    log = {\n",
    "        'tx':tx,\n",
    "        'timestamp':timestamp,\n",
    "        'pot_id':pot_id,\n",
    "        'integrator':integrator,\n",
    "        'pool':pool,\n",
    "        'from_address':from_address,\n",
    "        'amount_delta':amount_delta,\n",
    "        'action':action\n",
    "    }\n",
    "    log_list.append(log)\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract_to_token(contract):\n",
    "    \"\"\"\n",
    "    Maps contract addresses to their corresponding token symbols.\n",
    "    \n",
    "    This function takes a contract address and returns either the token symbol\n",
    "    or the contract address itself based on known mappings. It handles special cases\n",
    "    for specific contract addresses and empty strings.\n",
    "\n",
    "    Args:\n",
    "        contract (str): The contract address to map to a token symbol\n",
    "\n",
    "    Returns:\n",
    "        str: Either 'sUSD' for known stablecoin contracts, the original contract address,\n",
    "             or 'sUSD' for empty contract strings\n",
    "    \"\"\"\n",
    "    if contract == '0x0650caf159c5a49f711e8169d4336ecb9b950275':\n",
    "        return '0x0650caf159c5a49f711e8169d4336ecb9b950275'\n",
    "    elif contract == '0xa3931d71877C0E7a3148CB7Eb4463524FEc27fbD':\n",
    "        return 'sUSD'\n",
    "    elif contract == '':\n",
    "        slog(\"NO CONTRACT\") \n",
    "        return 'sUSD'\n",
    "    else:\n",
    "        return contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkPots(pots, cutoff):\n",
    "    \"\"\"\n",
    "    Validates pot balances against event logs up to a cutoff timestamp.\n",
    "    \n",
    "    This function is used for debugging to verify that the calculated pot balances\n",
    "    match the expected state based on historical events. It checks each contract's\n",
    "    pot balances against the event logs to detect any discrepancies.\n",
    "\n",
    "    Args:\n",
    "        pots (list): List of pot dictionaries containing balance information\n",
    "        cutoff (datetime): Timestamp to check balances up to\n",
    "\n",
    "    Returns:\n",
    "        bool: True if any errors were found, False if all balances match expected state\n",
    "\n",
    "    Usage:\n",
    "        # Example usage for debugging:\n",
    "        pots = [...] # List of pot states\n",
    "        cutoff = pd.Timestamp('2024-01-01')\n",
    "        has_errors = checkPots(pots, cutoff)\n",
    "        if has_errors:\n",
    "            print(\"Found balance discrepancies\")\n",
    "    \"\"\"\n",
    "    dfPots = pd.DataFrame(pots)\n",
    "    \n",
    "    dfRelEventsRefc = dfRelEventsRef[dfRelEventsRef['block_timestamp'] <= cutoff]\n",
    "    error = False\n",
    "    global contracts\n",
    "    for c in range(len(contracts)):\n",
    "        error = checkContract(c, dfPots, dfRelEventsRefc) or error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def withdrawFromPot(parsedEvent:rd.ReferralTransferDecoded, currentTxHash, pots, p_contract=None, \n",
    "                    p_liquidity_token=None, change_type='undefined', potnum:PotNumHolder = None, log_list = None):\n",
    "    \"\"\"\n",
    "    Process a withdrawal or transfer from a pot, updating balances and tracking changes.\n",
    "    \n",
    "    Args:\n",
    "        parsedEvent: The decoded transfer event containing amount and address info\n",
    "        currentTxHash: Hash of the current transaction\n",
    "        pots: List of pot dictionaries to update\n",
    "        p_contract: Optional contract address to filter pots\n",
    "        p_liquidity_token: Optional liquidity token to filter pots \n",
    "        change_type: Type of change ('withdraw' or 'transfer')\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (end, balance_changes, transfer_changes)\n",
    "            end: Boolean indicating if processing should end\n",
    "            balance_changes: List of balance change records\n",
    "            transfer_changes: List of transfer change records\n",
    "    \"\"\"\n",
    "    balance_changes = []\n",
    "    transfer_changes = []\n",
    "    # Determine pot address based on change type\n",
    "    pot_og_address = parsedEvent.to_address if change_type == 'withdraw' else parsedEvent.from_address\n",
    "    end = False\n",
    "    f_pot = find_pot(pot_og_address, pots, contract=p_contract, liquidity_token=p_liquidity_token)\n",
    "    transferred = 0\n",
    "    booking_num = 0\n",
    "    refcode = None\n",
    "\n",
    "    # Process if pot is found\n",
    "    if f_pot is not None:\n",
    "        contract = f_pot['contract']\n",
    "        liquidity_token = f_pot['liquidity_token']\n",
    "        left = parsedEvent.value\n",
    "        refcode = f_pot['referral_code']\n",
    "        \n",
    "        # Process initial reduction from first pot\n",
    "        reduce = min(left, f_pot['amount'])\n",
    "        left -= reduce\n",
    "        transferred += reduce\n",
    "        trace = {'pot':f_pot['potnum'], 'tx':currentTxHash, 'amount':reduce, 'type':change_type}\n",
    "        tx_tace = [f_pot['TXtrace']]\n",
    "        f_pot['amount'] -= reduce\n",
    "        add_log(currentTxHash, parsedEvent.row['block_timestamp'], f_pot['potnum'], f_pot['referral_code'],\n",
    "                contract_to_token(parsedEvent.contract), parsedEvent.from_address, -1*reduce, change_type, log_list=log_list)\n",
    "\n",
    "        # Process remaining amount across multiple pots if needed\n",
    "        while left > 0 and f_pot:\n",
    "            f_pot = find_pot(pot_og_address, pots, contract=p_contract, liquidity_token=p_liquidity_token)\n",
    "            if f_pot is not None:\n",
    "                contract = f_pot['contract']\n",
    "                \n",
    "                # Handle case where referral code changes\n",
    "                if f_pot['referral_code'] != refcode:\n",
    "                    if change_type == 'transfer':\n",
    "                        # Create new pot for transfer with different referral code\n",
    "                        slog('New code: Different referral code in transfer', currentTxHash)\n",
    "                        p = create_new_pot(refcode, parsedEvent.to_address, transferred,\n",
    "                                        parsedEvent.tx_hash, contract, liquidity_token, spawn='transfer',\n",
    "                                        previous_pot_trace=trace, pot_num=potnum)\n",
    "                        pots.append(p)\n",
    "                        add_log(currentTxHash, parsedEvent.row['block_timestamp'], p['potnum'], refcode,\n",
    "                                contract_to_token(parsedEvent.contract), parsedEvent.from_address, parsedEvent.value, 'transfer',log_list=log_list)\n",
    "                        transfer_change = {'ref_code':str(refcode),\n",
    "                                        'amount':transferred,\n",
    "                                        'timestamp':parsedEvent.row['block_timestamp'],\n",
    "                                        'block_number':parsedEvent.row['block_number'],\n",
    "                                        'event_index':parsedEvent.event_index,\n",
    "                                        'from':parsedEvent.from_address,\n",
    "                                        'to':parsedEvent.to_address,\n",
    "                                        'type':'transfer',\n",
    "                                        'booking_num':booking_num,\n",
    "                                        'contract':parsedEvent.contract, 'tx':currentTxHash}\n",
    "                        transfer_changes.append(transfer_change)\n",
    "                        booking_num += 1\n",
    "                        transferred = 0\n",
    "                        trace = []\n",
    "                        tx_tace = []\n",
    "                        refcode = f_pot['referral_code']\n",
    "                    else:\n",
    "                        # Record balance change for withdrawal with different referral code\n",
    "                        balance_change = {'ref_code':str(refcode), 'amount':transferred * -1,\n",
    "                                        'timestamp':parsedEvent.row['block_timestamp'],\n",
    "                                        'block_number':parsedEvent.row['block_number'],\n",
    "                                        'event_index':parsedEvent.event_index,\n",
    "                                        'from':parsedEvent.from_address,\n",
    "                                        'type':change_type,\n",
    "                                        'booking_num':booking_num,\n",
    "                                        'contract':parsedEvent.contract, 'tx':currentTxHash}\n",
    "                        balance_changes.append(balance_change)\n",
    "                        booking_num += 1\n",
    "                        transferred = 0\n",
    "                        refcode = f_pot['referral_code']\n",
    "\n",
    "                # Process reduction from current pot\n",
    "                reduce = min(left, f_pot['amount'])\n",
    "                left -= reduce\n",
    "                add_log(currentTxHash, parsedEvent.row['block_timestamp'], f_pot['potnum'], f_pot['referral_code'],\n",
    "                        contract_to_token(parsedEvent.contract), parsedEvent.from_address, -1*reduce, change_type,log_list=log_list)\n",
    "                transferred += reduce\n",
    "                f_pot['amount'] -= reduce\n",
    "                trace = {'pot':f_pot['potnum'], 'tx':currentTxHash, 'amount':reduce, 'type':change_type}\n",
    "                tx_tace.append(f_pot['TXtrace'])\n",
    "            else:\n",
    "                # Handle insufficient funds error\n",
    "                slog('ERROR: Not enough funds in pot withdraw', currentTxHash, 'left', left/1e18, 'withdraw from', pot_og_address)\n",
    "                if left/1e18 > 1:\n",
    "                    end = True\n",
    "                else:\n",
    "                    slog('ERROR too small, ignored')\n",
    "                break\n",
    "\n",
    "        # Final processing based on change type\n",
    "        if change_type == 'transfer':\n",
    "            if left > 0:\n",
    "                slog(\"ERROR left over in transfer\", currentTxHash, left)\n",
    "            p = create_new_pot(refcode, parsedEvent.to_address, transferred, parsedEvent.tx_hash,\n",
    "                            parsedEvent.contract, liquidity_token, spawn='transfer',\n",
    "                            previous_pot_trace=trace, pot_num=potnum)\n",
    "            pots.append(p)\n",
    "            add_log(currentTxHash, parsedEvent.row['block_timestamp'], p['potnum'], refcode,\n",
    "                    contract_to_token(parsedEvent.contract), parsedEvent.from_address, parsedEvent.value, 'transfer',log_list=log_list)\n",
    "            transfer_change = {'ref_code':str(refcode),\n",
    "                            'amount':transferred,\n",
    "                            'type':'transfer',\n",
    "                            'timestamp':parsedEvent.row['block_timestamp'],\n",
    "                            'block_number':parsedEvent.row['block_number'],\n",
    "                            'event_index':parsedEvent.event_index,\n",
    "                            'from':parsedEvent.from_address,\n",
    "                            'to':parsedEvent.to_address,\n",
    "                            'booking_num':booking_num,\n",
    "                            'contract':parsedEvent.contract, 'tx':currentTxHash}\n",
    "            transfer_changes.append(transfer_change)\n",
    "            booking_num += 1\n",
    "        else:\n",
    "            # Record final balance change for withdrawal\n",
    "            balance_change = {'ref_code':str(refcode),\n",
    "                            'amount':transferred * -1,\n",
    "                            'timestamp':parsedEvent.row['block_timestamp'],\n",
    "                            'contract':parsedEvent.contract,\n",
    "                            'block_number':parsedEvent.row['block_number'],\n",
    "                            'event_index':parsedEvent.event_index,\n",
    "                            'type':change_type,\n",
    "                            'from':parsedEvent.from_address,\n",
    "                            'booking_num':booking_num,\n",
    "                            'tx':currentTxHash}\n",
    "            balance_changes.append(balance_change)\n",
    "            booking_num += 1\n",
    "            transferred = 0\n",
    "            if left > 0:\n",
    "                slog(\"ERROR left over in withdraw\", currentTxHash, left)\n",
    "    else:\n",
    "        # Handle case where no pot is found\n",
    "        slog('ERROR: No pot found in ', change_type, currentTxHash, parsedEvent)\n",
    "        if parsedEvent.value/1e18 > 1:\n",
    "            end = True\n",
    "        else:\n",
    "            slog('ERROR too small, ignored', parsedEvent.value/1e18)\n",
    "\n",
    "    return end, balance_changes, transfer_changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dfTraceEvents, contracts, dfsUSDSPrices, reward_percentage, slog=print):    \n",
    "    dfUSDSB =  dfSFLogs[dfSFLogs['event_name'].isin(['withdrawn','deposit','withdraw']) & (dfSFLogs['contract_address'].str.lower() == contracts[-1].lower())]\n",
    "    # generate sanity-check event relative to stake or withdraw\n",
    "    dfUSDSB['am'] = dfUSDSB.apply(lambda x: int(x['dl']['shares'])if x['event_name'] == 'deposit' else -1*int(x['dl']['shares']), axis=1)\n",
    "    dfSFStakeWithdraw = dfSFLogs[dfSFLogs['event_name'].isin(['withdrawn','staked']) & (dfSFLogs['contract_address'].str.lower() == contracts[0].lower())]\n",
    "\n",
    "    dfSFStakeWithdraw['am'] = dfSFStakeWithdraw.apply(lambda x: int(x['dl']['amount'])if x['event_name'] == 'staked' else -1*int(x['dl']['amount']), axis=1)\n",
    "\n",
    "    potnum = PotNumHolder()\n",
    "    idxcnt = 0\n",
    "    pots = []\n",
    "    gstaked = {c:0 for c in contracts}\n",
    "    potsOverTime = {}\n",
    "    log_list = []\n",
    "\n",
    "    ##generate empty pot and start and end of month checkpoints\n",
    "    # Get all unique referral codes from events\n",
    "    all_refs = dfTraceEvents['dl'].apply(lambda x: str(x.get('referral', 'untagged'))).dropna().astype(str).unique().tolist()\n",
    "    all_refs.sort()\n",
    "\n",
    "    slog(\"USING REFS:\",all_refs, \"of\", dfTraceEvents.shape)\n",
    "\n",
    "    import itertools\n",
    "\n",
    "    # Helper function to create empty checkpoints for all contract/ref code combinations\n",
    "    # These checkpoints help track balances at specific timestamps\n",
    "    def empty_for_all(timestamp):\n",
    "        ret = []\n",
    "        for perm in itertools.product(contracts,all_refs):\n",
    "            ret.append( {'ref_code': str(perm[1]),\n",
    "            'amount': 0,\n",
    "            'timestamp': timestamp,\n",
    "            'contract': perm[0],\n",
    "            'type':'checkpoint',\n",
    "            'tx': f'virtual_{timestamp}_{perm[0]}_{perm[1]}'})\n",
    "        return ret\n",
    "\n",
    "    # Initialize tracking variables\n",
    "    timer = time.time()\n",
    "    end = False\n",
    "    currentMonth = dfTraceEvents.iloc[0]['block_timestamp'].to_period('M')\n",
    "    lastTime = dfTraceEvents.iloc[0]['block_timestamp']\n",
    "    lastHash = None\n",
    "    balance_history = []  # Tracks all balance changes\n",
    "    transfer_history = [] # Tracks token transfers between addresses\n",
    "    balance_history.extend(empty_for_all(currentMonth.to_timestamp()))\n",
    "\n",
    "    # Main event processing loop\n",
    "    while dfTraceEvents.shape[0] > 0 and not end:\n",
    "        # Handle month transitions\n",
    "        # At each month boundary, we create checkpoints to track historical balances\n",
    "        nextMonth = dfTraceEvents.iloc[0]['block_timestamp'].to_period('M')\n",
    "        if nextMonth != currentMonth:\n",
    "            # Add checkpoints at month boundaries\n",
    "            balance_history.extend(empty_for_all(nextMonth.to_timestamp()-pd.Timedelta('1s')))\n",
    "            potsOverTime[currentMonth.strftime('%Y-%m')] = [copy.deepcopy(p) for p in pots]\n",
    "            balance_history.extend(empty_for_all(nextMonth.to_timestamp()))\n",
    "            slog('MONTH SAVED', currentMonth, '->', nextMonth, 'Augmented Timelines', nextMonth.to_timestamp()-pd.Timedelta('1s'),nextMonth.to_timestamp())\n",
    "            currentMonth = nextMonth\n",
    "\n",
    "        # Process events in current transaction\n",
    "        currentTxHash = dfTraceEvents.iloc[0]['tx_hash']\n",
    "        currentTxEvents = dfTraceEvents[dfTraceEvents['tx_hash'] == currentTxHash]\n",
    "\n",
    "        # Validate pot state to ensure consistency\n",
    "        if currentTxEvents['block_timestamp'].max() > lastTime and checkFrom < lastTime:\n",
    "            check = checkPots(pots,lastTime)\n",
    "            if check:\n",
    "                slog('ERROR: Pots do not match events', 'last tx', lastHash, 'current tx', currentTxHash)\n",
    "                break\n",
    "\n",
    "        # Initialize event processing for this transaction\n",
    "        to_process_events:list[rd.ReferralTransferDecoded] = []\n",
    "        idxcnt +=currentTxEvents.shape[0]\n",
    "        \n",
    "        if idxcnt % 1000 == 0:\n",
    "            slog(idxcnt)\n",
    "        \n",
    "        # Process stake/deposit events\n",
    "        # These events represent users staking tokens or depositing into the protocol\n",
    "        if 'staked' in currentTxEvents['event_name'].values or 'deposit' in currentTxEvents['event_name'].values:\n",
    "            eventCandidate = currentTxEvents[currentTxEvents['event_name'].str.lower().isin(['staked','deposit'])]\n",
    "            if eventCandidate.shape[0] == 1:\n",
    "                to_process_events.append(rd.ReferralTransferDecoded(eventCandidate.iloc[0]))\n",
    "            elif eventCandidate.shape[0] > 1:\n",
    "                to_process_events = to_process_events + [rd.ReferralTransferDecoded(r[1]) for r in eventCandidate.iterrows()]\n",
    "            else:\n",
    "                slog('No staked events in current tx', currentTxHash)\n",
    "\n",
    "        # Process transfer events\n",
    "        # These represent token transfers between addresses, excluding mints and burns\n",
    "        if 'transfer' in currentTxEvents['event_name'].values:\n",
    "            eventCandidate = currentTxEvents[currentTxEvents['event_name'].str.lower().isin(['transfer'])]\n",
    "            refs = [rd.ReferralTransferDecoded(r[1]) for r in eventCandidate.iterrows()]\n",
    "            # Filter out mint/burn operations as they're handled differently\n",
    "            to_process_events = to_process_events + [r for r in refs if not r.mint and not r.burn]\n",
    "\n",
    "        # Process referral events\n",
    "        # These events track referral relationships and rewards\n",
    "        if 'referral' in currentTxEvents['event_name'].values:\n",
    "            eventCandidate = currentTxEvents[currentTxEvents['event_name'].str.lower().isin([ 'referral'])]\n",
    "            refs = []\n",
    "            if eventCandidate.shape[0] == 1:\n",
    "                refs.append(rd.ReferralTransferDecoded(eventCandidate.iloc[0]))\n",
    "            elif eventCandidate.shape[0] > 1:\n",
    "                for r in eventCandidate.iterrows():\n",
    "                    refs.append(rd.ReferralTransferDecoded(r[1]))\n",
    "            else:\n",
    "                slog('No Farm events in current tx', currentTxHash)\n",
    "            \n",
    "            for r in refs:\n",
    "                # Remove corresponding stake events to avoid double counting\n",
    "                # This is necessary because referral events often come with associated stake events\n",
    "                to_process_events = [x for x in to_process_events if not( \n",
    "                x.action == rd.ActionType.stake and x.from_address == r.from_address and x.value == r.value)]\n",
    "                to_process_events.append(r)\n",
    "\n",
    "        # Process withdrawal events\n",
    "        # These represent users withdrawing their tokens from the protocol\n",
    "        if 'withdrawn' in currentTxEvents['event_name'].values or  'withdraw' in currentTxEvents['event_name'].values:\n",
    "            eventCandidate = currentTxEvents[currentTxEvents['event_name'].str.lower().isin(['withdrawn','withdraw'])]\n",
    "            for r in eventCandidate.iterrows():\n",
    "                to_process_events.append(rd.ReferralTransferDecoded(r[1]))\n",
    "\n",
    "        # Sort and process all events by their index to maintain correct order\n",
    "        to_process_events = sorted(to_process_events, key=lambda x: x.event_index)\n",
    "        for e in to_process_events:\n",
    "            parsedEvent = e\n",
    "            \n",
    "            # Validate referral code exists in our known set\n",
    "            if parsedEvent.code is not None and str(parsedEvent.code) not in all_refs:\n",
    "                slog('!!ERROR!!: New UNKNOWN referral code in tx', currentTxHash,parsedEvent.code)\n",
    "\n",
    "            # Handle referral events\n",
    "            # These create new pots for tracking referral rewards\n",
    "            if parsedEvent.action == rd.ActionType.referral:\n",
    "                if parsedEvent.code is not None:\n",
    "                    # Update global staked amount for this contract\n",
    "                    gstaked[parsedEvent.contract] += parsedEvent.value\n",
    "                    # Create new pot for referral tracking\n",
    "                    p=create_new_pot(\n",
    "                    parsedEvent.code,\n",
    "                    parsedEvent.from_address,\n",
    "                    parsedEvent.value, \n",
    "                    parsedEvent.tx_hash, \n",
    "                    parsedEvent.contract,\n",
    "                    contract_to_token(parsedEvent.contract),\n",
    "                    previous_pot_trace=[{'pot':'spawn', 'tx':currentTxHash, 'amount':parsedEvent.value}],\n",
    "                        spawn = 'ref', pot_num=potnum)\n",
    "                    # Record balance change\n",
    "                    balance_change = {'ref_code':parsedEvent.code, \n",
    "                                    'amount':parsedEvent.value, \n",
    "                                    'timestamp':parsedEvent.row['block_timestamp'],\n",
    "                                    'block_number':parsedEvent.row['block_number'],\n",
    "                                    'event_index':parsedEvent.event_index,\n",
    "                                    'to':parsedEvent.from_address,\n",
    "                                    'type':'referral',\n",
    "                                    'contract':parsedEvent.contract, \n",
    "                                    'booking_num':0,\n",
    "                                    'tx':currentTxHash}\n",
    "                    balance_history.append(balance_change)\n",
    "                    pots.append(p)\n",
    "                    add_log(currentTxHash, parsedEvent.row['block_timestamp'], p['potnum'], parsedEvent.code, contract_to_token(parsedEvent.contract), parsedEvent.from_address, parsedEvent.value, 'referral',log_list=log_list)\n",
    "                else:\n",
    "                    slog('ERROR: No referral code in tx', currentTxHash)\n",
    "\n",
    "            # Handle withdrawal events\n",
    "            # These reduce pot balances and record withdrawals\n",
    "            elif parsedEvent.action == rd.ActionType.withdraw:\n",
    "                    f_pot = find_pot(parsedEvent.to_address, pots, contract=parsedEvent.contract)\n",
    "                    tend, balance_changes, transfer_changes = withdrawFromPot(parsedEvent, currentTxHash, pots,p_contract=parsedEvent.contract, change_type='withdraw', potnum=potnum,log_list=log_list)\n",
    "                    balance_history.extend(balance_changes)\n",
    "                    transfer_history.extend(transfer_changes)\n",
    "                    end = end or tend\n",
    "\n",
    "            # Handle stake events\n",
    "            # These create new pots for tracking staked tokens\n",
    "            elif parsedEvent.action == rd.ActionType.stake:\n",
    "                gstaked[parsedEvent.contract] += parsedEvent.value\n",
    "                p = create_new_pot(\n",
    "                    parsedEvent.code,\n",
    "                    parsedEvent.from_address,\n",
    "                    parsedEvent.value, \n",
    "                    parsedEvent.tx_hash, \n",
    "                    parsedEvent.contract, \n",
    "                    contract_to_token(parsedEvent.contract),\n",
    "                    previous_pot_trace=[{'pot':'spawn', 'tx':currentTxHash, 'amount':parsedEvent.value}],\n",
    "                    spawn='stake', pot_num=potnum)\n",
    "                balance_change = {'ref_code':parsedEvent.code, \n",
    "                                'amount':parsedEvent.value, \n",
    "                                'timestamp':parsedEvent.row['block_timestamp'],\n",
    "                                'block_number':parsedEvent.row['block_number'],\n",
    "                                'event_index':parsedEvent.event_index,\n",
    "                                'from':parsedEvent.from_address,\n",
    "                                'type':'stake',\n",
    "                                'booking_num':0,\n",
    "                                'contract':parsedEvent.contract, 'tx':currentTxHash}\n",
    "                balance_history.append(balance_change)\n",
    "                pots.append(p)\n",
    "                add_log(currentTxHash, parsedEvent.row['block_timestamp'], p['potnum'], parsedEvent.code, \n",
    "                        contract_to_token(parsedEvent.contract), parsedEvent.from_address, parsedEvent.value, 'stake')\n",
    "\n",
    "            # Handle transfer events\n",
    "            # These track token movements between addresses\n",
    "            elif parsedEvent.type == rd.TransactionType.transfer:\n",
    "                liquidity_token = parsedEvent.contract\n",
    "                tend, _, transfer_changes = withdrawFromPot(parsedEvent, currentTxHash,pots, p_liquidity_token=liquidity_token, change_type='transfer',potnum=potnum, log_list=log_list)\n",
    "                end = end or tend\n",
    "                transfer_history.extend(transfer_changes)\n",
    "\n",
    "        # Update tracking state for next iteration\n",
    "        dfTraceEvents = dfTraceEvents[dfTraceEvents['tx_hash']!=(currentTxHash)]\n",
    "        lastTime = currentTxEvents['block_timestamp'].max()\n",
    "        lastHash = currentTxEvents['tx_hash'].max()\n",
    "\n",
    "    # Handle errors and finalize\n",
    "    if end:\n",
    "        slog('ERROR: Pots do not match events', 'last tx', lastHash, 'current tx', currentTxHash)\n",
    "        slog('shape:',dfTraceEvents.shape)\n",
    "        exit(1)\n",
    "    \n",
    "    # Save final state for current month\n",
    "    potsOverTime[currentMonth.strftime('%Y-%m')] = [copy.deepcopy(p) for p in pots]\n",
    "    slog('FUNDS TRACKED', time.time()-timer)\n",
    "\n",
    "    return pots, potsOverTime, balance_history, transfer_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2669817/889053538.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfUSDSB['am'] = dfUSDSB.apply(lambda x: int(x['dl']['shares'])if x['event_name'] == 'deposit' else -1*int(x['dl']['shares']), axis=1)\n",
      "/tmp/ipykernel_2669817/889053538.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfSFStakeWithdraw['am'] = dfSFStakeWithdraw.apply(lambda x: int(x['dl']['amount'])if x['event_name'] == 'staked' else -1*int(x['dl']['amount']), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING REFS: ['0', '1001', '1002', '1003', '1004', '1007', '13425', 'untagged'] of (5073, 13)\n",
      "1000\n",
      "2000\n",
      "MONTH SAVED 2024-09 -> 2024-10 Augmented Timelines 2024-09-30 23:59:59 2024-10-01 00:00:00\n",
      "New code: Different referral code in transfer 0x0ed2a0fd0ee2f561490bf363db382e2da0aeaa2f5b02b3908ddb944070ba16e9\n",
      "New code: Different referral code in transfer 0xb376975b8c9cf64c8946d8848db86292f862aaf2488c9b826d474a3238fdd514\n",
      "New code: Different referral code in transfer 0xfd7db0b7a5060d622e3f20901f62a5df793c5b5b835de954f651e3c7f699fd37\n",
      "4000\n",
      "5000\n",
      "FUNDS TRACKED 9.725681066513062\n"
     ]
    }
   ],
   "source": [
    "pots, potsOverTime, balance_history, transfer_history = main(dfTraceEvents, contracts, dfsUSDSPrices, reward_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>block_timestamp</th>\n",
       "      <th>block_number</th>\n",
       "      <th>tx_hash</th>\n",
       "      <th>event_name</th>\n",
       "      <th>dl</th>\n",
       "      <th>contract_address</th>\n",
       "      <th>contract_name</th>\n",
       "      <th>event_index</th>\n",
       "      <th>origin_function_signature</th>\n",
       "      <th>origin_from_address</th>\n",
       "      <th>origin_to_address</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77132</td>\n",
       "      <td>2024-09-17 12:02:23</td>\n",
       "      <td>20770201</td>\n",
       "      <td>0x2235921bb1db4353575e409d36d61aeffc9cca812582...</td>\n",
       "      <td>staked</td>\n",
       "      <td>{'amount': '442208517357432838538428', 'user':...</td>\n",
       "      <td>0x0650caf159c5a49f711e8169d4336ecb9b950275</td>\n",
       "      <td>None</td>\n",
       "      <td>466</td>\n",
       "      <td>0xa694fc3a</td>\n",
       "      <td>0x7052d6e780435e09901bd73ce280183f40a65459</td>\n",
       "      <td>0x0650caf159c5a49f711e8169d4336ecb9b950275</td>\n",
       "      <td>[\\n  \"0x9e71bc8eea02a63969f509818f2dafb9254532...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46740</td>\n",
       "      <td>2024-09-17 12:23:23</td>\n",
       "      <td>20770306</td>\n",
       "      <td>0x530da2be63244d31dd52590a49575d23fb3255803944...</td>\n",
       "      <td>staked</td>\n",
       "      <td>{'amount': '7500000000000000000000', 'user': '...</td>\n",
       "      <td>0x0650caf159c5a49f711e8169d4336ecb9b950275</td>\n",
       "      <td>None</td>\n",
       "      <td>208</td>\n",
       "      <td>0x6a761202</td>\n",
       "      <td>0xb8ab6829ed0e1484050edfdfec93fceac9cac54b</td>\n",
       "      <td>0xbfc30a7b66d913c75c63ddcaaaa12e55821fc12d</td>\n",
       "      <td>[\\n  \"0x9e71bc8eea02a63969f509818f2dafb9254532...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46754</td>\n",
       "      <td>2024-09-17 12:36:47</td>\n",
       "      <td>20770372</td>\n",
       "      <td>0xae678e9069e0bfe775d1691267e6069c7918d596bab1...</td>\n",
       "      <td>staked</td>\n",
       "      <td>{'amount': '141738000000000000000000', 'user':...</td>\n",
       "      <td>0x0650caf159c5a49f711e8169d4336ecb9b950275</td>\n",
       "      <td>None</td>\n",
       "      <td>107</td>\n",
       "      <td>0xa694fc3a</td>\n",
       "      <td>0x344d9c4f488bb5519d390304457d64034618145c</td>\n",
       "      <td>0x0650caf159c5a49f711e8169d4336ecb9b950275</td>\n",
       "      <td>[\\n  \"0x9e71bc8eea02a63969f509818f2dafb9254532...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46796</td>\n",
       "      <td>2024-09-17 12:42:59</td>\n",
       "      <td>20770403</td>\n",
       "      <td>0x503d941e3efb4e496da6eaf6f64336f6a9c1065c968a...</td>\n",
       "      <td>staked</td>\n",
       "      <td>{'amount': '400000000000000000000000', 'user':...</td>\n",
       "      <td>0x0650caf159c5a49f711e8169d4336ecb9b950275</td>\n",
       "      <td>None</td>\n",
       "      <td>265</td>\n",
       "      <td>0xa694fc3a</td>\n",
       "      <td>0x344d9c4f488bb5519d390304457d64034618145c</td>\n",
       "      <td>0x0650caf159c5a49f711e8169d4336ecb9b950275</td>\n",
       "      <td>[\\n  \"0x9e71bc8eea02a63969f509818f2dafb9254532...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45211</td>\n",
       "      <td>2024-09-17 12:47:59</td>\n",
       "      <td>20770428</td>\n",
       "      <td>0x43df1618391794cb266020f80a9bb842de49a8f2d605...</td>\n",
       "      <td>staked</td>\n",
       "      <td>{'amount': '1000000000000000000000', 'user': '...</td>\n",
       "      <td>0x10ab606b067c9c461d8893c47c7512472e19e2ce</td>\n",
       "      <td>None</td>\n",
       "      <td>356</td>\n",
       "      <td>0xa694fc3a</td>\n",
       "      <td>0x4178824eac1d03445477772e71f4a53a5ee53184</td>\n",
       "      <td>0x10ab606b067c9c461d8893c47c7512472e19e2ce</td>\n",
       "      <td>[\\n  \"0x9e71bc8eea02a63969f509818f2dafb9254532...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>46962</td>\n",
       "      <td>2024-10-14 21:22:47</td>\n",
       "      <td>20966461</td>\n",
       "      <td>0x2d3cebb83046389675df27af965ec82c2fc3085dc3c9...</td>\n",
       "      <td>withdraw</td>\n",
       "      <td>{'assets': '873997403724916627273173', 'owner'...</td>\n",
       "      <td>0xa3931d71877c0e7a3148cb7eb4463524fec27fbd</td>\n",
       "      <td>Savings USDS</td>\n",
       "      <td>529</td>\n",
       "      <td>0x22bee494</td>\n",
       "      <td>0x0a4d75ab96375e37211cd00a842d77d0519eed1b</td>\n",
       "      <td>0x604e586f17ce106b64185a7a0d2c1da5bace711e</td>\n",
       "      <td>[\\n  \"0xfbde797d201c681b91056529119e0b02407c7b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>34934</td>\n",
       "      <td>2024-10-14 21:40:59</td>\n",
       "      <td>20966552</td>\n",
       "      <td>0xfce92c5fcbc154d4299fdd40536c683e050cfc905aa3...</td>\n",
       "      <td>deposit</td>\n",
       "      <td>{'assets': '624493202285950034386372', 'owner'...</td>\n",
       "      <td>0xa3931d71877c0e7a3148cb7eb4463524fec27fbd</td>\n",
       "      <td>Savings USDS</td>\n",
       "      <td>205</td>\n",
       "      <td>0x6a761202</td>\n",
       "      <td>0xea1b76f2cd671cfe29893b4ac778d22511058048</td>\n",
       "      <td>0x485947c54ac21c6317559c88440d7d2394352716</td>\n",
       "      <td>[\\n  \"0xdcbc1c05240f31ff3ad067ef1ee35ce4997762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5070</th>\n",
       "      <td>86728</td>\n",
       "      <td>2024-10-14 21:40:59</td>\n",
       "      <td>20966552</td>\n",
       "      <td>0xfce92c5fcbc154d4299fdd40536c683e050cfc905aa3...</td>\n",
       "      <td>transfer</td>\n",
       "      <td>{'from': '0x0000000000000000000000000000000000...</td>\n",
       "      <td>0xa3931d71877c0e7a3148cb7eb4463524fec27fbd</td>\n",
       "      <td>Savings USDS</td>\n",
       "      <td>206</td>\n",
       "      <td>0x6a761202</td>\n",
       "      <td>0xea1b76f2cd671cfe29893b4ac778d22511058048</td>\n",
       "      <td>0x485947c54ac21c6317559c88440d7d2394352716</td>\n",
       "      <td>[\\n  \"0xddf252ad1be2c89b69c2b068fc378daa952ba7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5071</th>\n",
       "      <td>58353</td>\n",
       "      <td>2024-10-14 22:11:35</td>\n",
       "      <td>20966704</td>\n",
       "      <td>0xe85726021ce0d69a00a5450bb0fe4ed757866377c3f2...</td>\n",
       "      <td>withdrawn</td>\n",
       "      <td>{'amount': '819028640110005629734981', 'user':...</td>\n",
       "      <td>0x0650caf159c5a49f711e8169d4336ecb9b950275</td>\n",
       "      <td>None</td>\n",
       "      <td>399</td>\n",
       "      <td>0x22bee494</td>\n",
       "      <td>0x0a4d75ab96375e37211cd00a842d77d0519eed1b</td>\n",
       "      <td>0x604e586f17ce106b64185a7a0d2c1da5bace711e</td>\n",
       "      <td>[\\n  \"0x7084f5476618d8e60b11ef0d7d3f06914655ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>28711</td>\n",
       "      <td>2024-10-14 22:11:35</td>\n",
       "      <td>20966704</td>\n",
       "      <td>0x560d59ef9371b3fc240f92b5466d5936b584a1440a8b...</td>\n",
       "      <td>deposit</td>\n",
       "      <td>{'assets': '608487599326040055450662', 'owner'...</td>\n",
       "      <td>0xa3931d71877c0e7a3148cb7eb4463524fec27fbd</td>\n",
       "      <td>Savings USDS</td>\n",
       "      <td>424</td>\n",
       "      <td>0x22bee494</td>\n",
       "      <td>0x0a4d75ab96375e37211cd00a842d77d0519eed1b</td>\n",
       "      <td>0x604e586f17ce106b64185a7a0d2c1da5bace711e</td>\n",
       "      <td>[\\n  \"0xdcbc1c05240f31ff3ad067ef1ee35ce4997762...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5073 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index     block_timestamp  block_number  \\\n",
       "0     77132 2024-09-17 12:02:23      20770201   \n",
       "1     46740 2024-09-17 12:23:23      20770306   \n",
       "2     46754 2024-09-17 12:36:47      20770372   \n",
       "3     46796 2024-09-17 12:42:59      20770403   \n",
       "4     45211 2024-09-17 12:47:59      20770428   \n",
       "...     ...                 ...           ...   \n",
       "5068  46962 2024-10-14 21:22:47      20966461   \n",
       "5069  34934 2024-10-14 21:40:59      20966552   \n",
       "5070  86728 2024-10-14 21:40:59      20966552   \n",
       "5071  58353 2024-10-14 22:11:35      20966704   \n",
       "5072  28711 2024-10-14 22:11:35      20966704   \n",
       "\n",
       "                                                tx_hash event_name  \\\n",
       "0     0x2235921bb1db4353575e409d36d61aeffc9cca812582...     staked   \n",
       "1     0x530da2be63244d31dd52590a49575d23fb3255803944...     staked   \n",
       "2     0xae678e9069e0bfe775d1691267e6069c7918d596bab1...     staked   \n",
       "3     0x503d941e3efb4e496da6eaf6f64336f6a9c1065c968a...     staked   \n",
       "4     0x43df1618391794cb266020f80a9bb842de49a8f2d605...     staked   \n",
       "...                                                 ...        ...   \n",
       "5068  0x2d3cebb83046389675df27af965ec82c2fc3085dc3c9...   withdraw   \n",
       "5069  0xfce92c5fcbc154d4299fdd40536c683e050cfc905aa3...    deposit   \n",
       "5070  0xfce92c5fcbc154d4299fdd40536c683e050cfc905aa3...   transfer   \n",
       "5071  0xe85726021ce0d69a00a5450bb0fe4ed757866377c3f2...  withdrawn   \n",
       "5072  0x560d59ef9371b3fc240f92b5466d5936b584a1440a8b...    deposit   \n",
       "\n",
       "                                                     dl  \\\n",
       "0     {'amount': '442208517357432838538428', 'user':...   \n",
       "1     {'amount': '7500000000000000000000', 'user': '...   \n",
       "2     {'amount': '141738000000000000000000', 'user':...   \n",
       "3     {'amount': '400000000000000000000000', 'user':...   \n",
       "4     {'amount': '1000000000000000000000', 'user': '...   \n",
       "...                                                 ...   \n",
       "5068  {'assets': '873997403724916627273173', 'owner'...   \n",
       "5069  {'assets': '624493202285950034386372', 'owner'...   \n",
       "5070  {'from': '0x0000000000000000000000000000000000...   \n",
       "5071  {'amount': '819028640110005629734981', 'user':...   \n",
       "5072  {'assets': '608487599326040055450662', 'owner'...   \n",
       "\n",
       "                                contract_address contract_name  event_index  \\\n",
       "0     0x0650caf159c5a49f711e8169d4336ecb9b950275          None          466   \n",
       "1     0x0650caf159c5a49f711e8169d4336ecb9b950275          None          208   \n",
       "2     0x0650caf159c5a49f711e8169d4336ecb9b950275          None          107   \n",
       "3     0x0650caf159c5a49f711e8169d4336ecb9b950275          None          265   \n",
       "4     0x10ab606b067c9c461d8893c47c7512472e19e2ce          None          356   \n",
       "...                                          ...           ...          ...   \n",
       "5068  0xa3931d71877c0e7a3148cb7eb4463524fec27fbd  Savings USDS          529   \n",
       "5069  0xa3931d71877c0e7a3148cb7eb4463524fec27fbd  Savings USDS          205   \n",
       "5070  0xa3931d71877c0e7a3148cb7eb4463524fec27fbd  Savings USDS          206   \n",
       "5071  0x0650caf159c5a49f711e8169d4336ecb9b950275          None          399   \n",
       "5072  0xa3931d71877c0e7a3148cb7eb4463524fec27fbd  Savings USDS          424   \n",
       "\n",
       "     origin_function_signature                         origin_from_address  \\\n",
       "0                   0xa694fc3a  0x7052d6e780435e09901bd73ce280183f40a65459   \n",
       "1                   0x6a761202  0xb8ab6829ed0e1484050edfdfec93fceac9cac54b   \n",
       "2                   0xa694fc3a  0x344d9c4f488bb5519d390304457d64034618145c   \n",
       "3                   0xa694fc3a  0x344d9c4f488bb5519d390304457d64034618145c   \n",
       "4                   0xa694fc3a  0x4178824eac1d03445477772e71f4a53a5ee53184   \n",
       "...                        ...                                         ...   \n",
       "5068                0x22bee494  0x0a4d75ab96375e37211cd00a842d77d0519eed1b   \n",
       "5069                0x6a761202  0xea1b76f2cd671cfe29893b4ac778d22511058048   \n",
       "5070                0x6a761202  0xea1b76f2cd671cfe29893b4ac778d22511058048   \n",
       "5071                0x22bee494  0x0a4d75ab96375e37211cd00a842d77d0519eed1b   \n",
       "5072                0x22bee494  0x0a4d75ab96375e37211cd00a842d77d0519eed1b   \n",
       "\n",
       "                               origin_to_address  \\\n",
       "0     0x0650caf159c5a49f711e8169d4336ecb9b950275   \n",
       "1     0xbfc30a7b66d913c75c63ddcaaaa12e55821fc12d   \n",
       "2     0x0650caf159c5a49f711e8169d4336ecb9b950275   \n",
       "3     0x0650caf159c5a49f711e8169d4336ecb9b950275   \n",
       "4     0x10ab606b067c9c461d8893c47c7512472e19e2ce   \n",
       "...                                          ...   \n",
       "5068  0x604e586f17ce106b64185a7a0d2c1da5bace711e   \n",
       "5069  0x485947c54ac21c6317559c88440d7d2394352716   \n",
       "5070  0x485947c54ac21c6317559c88440d7d2394352716   \n",
       "5071  0x604e586f17ce106b64185a7a0d2c1da5bace711e   \n",
       "5072  0x604e586f17ce106b64185a7a0d2c1da5bace711e   \n",
       "\n",
       "                                                 topics  \n",
       "0     [\\n  \"0x9e71bc8eea02a63969f509818f2dafb9254532...  \n",
       "1     [\\n  \"0x9e71bc8eea02a63969f509818f2dafb9254532...  \n",
       "2     [\\n  \"0x9e71bc8eea02a63969f509818f2dafb9254532...  \n",
       "3     [\\n  \"0x9e71bc8eea02a63969f509818f2dafb9254532...  \n",
       "4     [\\n  \"0x9e71bc8eea02a63969f509818f2dafb9254532...  \n",
       "...                                                 ...  \n",
       "5068  [\\n  \"0xfbde797d201c681b91056529119e0b02407c7b...  \n",
       "5069  [\\n  \"0xdcbc1c05240f31ff3ad067ef1ee35ce4997762...  \n",
       "5070  [\\n  \"0xddf252ad1be2c89b69c2b068fc378daa952ba7...  \n",
       "5071  [\\n  \"0x7084f5476618d8e60b11ef0d7d3f06914655ad...  \n",
       "5072  [\\n  \"0xdcbc1c05240f31ff3ad067ef1ee35ce4997762...  \n",
       "\n",
       "[5073 rows x 13 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTraceEvents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2663"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using reward %: 0.004 on total seconds: 31536000\n",
      "___________ 0x0650caf159c5a49f711e8169d4336ecb9b950275 untagged 0 ___________\n",
      "___________ 0xa3931d71877c0e7a3148cb7eb4463524fec27fbd untagged 1 ___________\n",
      "___________ 0x10ab606b067c9c461d8893c47c7512472e19e2ce untagged 2 ___________\n",
      "___________ 0xa3931d71877c0e7a3148cb7eb4463524fec27fbd 0 3 ___________\n",
      "___________ 0xa3931d71877c0e7a3148cb7eb4463524fec27fbd 1003 4 ___________\n",
      "___________ 0x0650caf159c5a49f711e8169d4336ecb9b950275 1001 5 ___________\n",
      "___________ 0xa3931d71877c0e7a3148cb7eb4463524fec27fbd 1001 6 ___________\n",
      "___________ 0x10ab606b067c9c461d8893c47c7512472e19e2ce 1001 7 ___________\n",
      "___________ 0x0650caf159c5a49f711e8169d4336ecb9b950275 1007 8 ___________\n",
      "___________ 0x0650caf159c5a49f711e8169d4336ecb9b950275 13425 9 ___________\n",
      "___________ 0xa3931d71877c0e7a3148cb7eb4463524fec27fbd 1002 10 ___________\n",
      "___________ 0xa3931d71877c0e7a3148cb7eb4463524fec27fbd 13425 11 ___________\n",
      "___________ 0xa3931d71877c0e7a3148cb7eb4463524fec27fbd 1004 12 ___________\n",
      "___________ 0x0650caf159c5a49f711e8169d4336ecb9b950275 0 13 ___________\n",
      "___________ 0x10ab606b067c9c461d8893c47c7512472e19e2ce 13425 14 ___________\n",
      "___________ 0x10ab606b067c9c461d8893c47c7512472e19e2ce 1007 15 ___________\n",
      "___________ 0x10ab606b067c9c461d8893c47c7512472e19e2ce 1003 16 ___________\n",
      "___________ 0x10ab606b067c9c461d8893c47c7512472e19e2ce 1002 17 ___________\n",
      "___________ 0x10ab606b067c9c461d8893c47c7512472e19e2ce 0 18 ___________\n",
      "___________ 0x0650caf159c5a49f711e8169d4336ecb9b950275 1004 19 ___________\n",
      "___________ 0x0650caf159c5a49f711e8169d4336ecb9b950275 1003 20 ___________\n",
      "___________ 0xa3931d71877c0e7a3148cb7eb4463524fec27fbd 1007 21 ___________\n",
      "___________ 0x0650caf159c5a49f711e8169d4336ecb9b950275 1002 22 ___________\n",
      "___________ 0x10ab606b067c9c461d8893c47c7512472e19e2ce 1004 23 ___________\n",
      "Done calculating rewards RangeIndex(start=0, stop=16, step=1)\n",
      "\n",
      "!!SANITY CHECKS!!\n",
      "OK!! Contract 0x0650caf159c5a49f711e8169d4336ecb9b950275 stake sum MATCH 430750768.8230557 430750768.8230557\n",
      "OK!! Contract 0x10ab606b067c9c461d8893c47c7512472e19e2ce stake sum MATCH 17567503.511681687 17567503.511681687\n",
      "OK!! Contract 0xa3931d71877c0e7a3148cb7eb4463524fec27fbd stake sum MATCH 507991178.6330394 507991178.6330394\n",
      "!!SANITY CHECKS!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "# Initialize logging and prepare balance history dataframe\n",
    "slog = print\n",
    "dfBH = pd.DataFrame(balance_history)\n",
    "dfBH['ref_code'] = dfBH['ref_code'].astype(str)\n",
    "code_contract_uniques = dfBH[['contract','ref_code']].value_counts().reset_index()\n",
    "\n",
    "# Constants for reward calculations\n",
    "total_seconds = 60 * 60 * 24 * 365\n",
    "slog(\"using reward %:\",reward_percentage, \"on total seconds:\", total_seconds)\n",
    "\n",
    "# Helper function to convert TVL to USD value for sUSDS token\n",
    "def rowToUSDValue(row):\n",
    "    #safety check to prevent accidental wrong usage,\n",
    "    # hence DF requires the contract field as well\n",
    "    if row['contract'] == '0xa3931d71877c0e7a3148cb7eb4463524fec27fbd'.lower():\n",
    "        month_price = dfsUSDSPrices[dfsUSDSPrices['month'] == row['month']]['price']\n",
    "        return row['eligible_tvl'] * month_price.values[0] if month_price.shape[0]>0 else row['eligible_tvl']\n",
    "    else:\n",
    "        print(\"wrong address called\")\n",
    "        return row['eligible_tvl']\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2592000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60*60*24 * 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next we generate cumsum and weighted TVL seconds from the given balance history (BH) data\n",
    "## Mathematical Explanation\n",
    "\n",
    "For each referral code and contract pair, we calculate:\n",
    "\n",
    "### 1. Cumulative Balance ($B_t$)\n",
    "$B_t = \\sum_{i=0}^t amount_i$\n",
    "\n",
    "Where $amount_i$ represents individual deposits/withdrawals\n",
    "\n",
    "### 2. Time Weight ($W_t$)\n",
    "The time weight factor ensures rewards are proportional to how long funds are held:\n",
    "\n",
    "$W_t = \\frac{t - t_{prev}}{seconds_{year}}$\n",
    "\n",
    "Where:\n",
    "- $t$ is the current timestamp\n",
    "- $t_{prev}$ is the previous timestamp \n",
    "- $seconds_{year}$ normalizes to annual basis (31,536,000 seconds)\n",
    "\n",
    "This creates proportional rewards by:\n",
    "1. Shorter holding periods result in smaller weights (e.g. 1 day = ~0.003)\n",
    "2. Longer holding periods have larger weights (e.g. 6 months = ~0.5) \n",
    "3. Annual normalization keeps rewards consistent regardless of time period\n",
    "\n",
    "For example:\n",
    "- $100 held for 1 day: $100 * (86400(60* 60 * 24)/31,536,000) = ~$0.27 weighted TVL\n",
    "- $100 held for 1 month: $100 * (2592000 (60* 60 * 24 * 30)/31,536,000) = ~$8.22 weighted TVL\n",
    "\n",
    "Where $t_{prev}$ is the previous timestamp\n",
    "\n",
    "### 3. TVL-seconds ($TVL_t$)\n",
    "$TVL_t = B_t \\times W_t$\n",
    "\n",
    "This weights the balance by duration held\n",
    "\n",
    "### 4. Monthly Eligible TVL\n",
    "$TVL_{month} = \\sum_{t \\in month} TVL_t$\n",
    "\n",
    "Final TVL is in USD terms (special conversion for sUSDS token)\n",
    "\n",
    "### Implementation Steps\n",
    "1. Group data by referral code & contract\n",
    "2. Sort by timestamp to calculate proper cumulative sums\n",
    "3. Calculate running balance using `cumsum()`\n",
    "4. Weight by held time (time diff between entries)\n",
    "5. Multiply balance  time weight for TVL-seconds\n",
    "6. Group by month and sum for monthly rewards\n",
    "7. Convert sUSDS token amounts to USD value\n",
    "8. Aggregate across all codes/contracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rewards for each referral code and contract combination\n",
    "dfBHs = []\n",
    "dfBHsR = []\n",
    "dfRewards = None\n",
    "i = 0\n",
    "for r in code_contract_uniques.iterrows():\n",
    "    # Get data for current contract/ref code pair\n",
    "    current_contract = r[1]['contract']\n",
    "    dfBHt = dfBH[(dfBH['contract'] == current_contract) & (dfBH['ref_code'] == r[1]['ref_code'])].copy()\n",
    "    dfBHt.sort_values('timestamp',inplace=True)\n",
    "    dfBHsR.append(dfBHt)\n",
    "    \n",
    "    # Calculate cumulative sums and TVL\n",
    "    dfBHt.loc[:,'cumsum'] = dfBHt['amount'].cumsum()\n",
    "    dfBHt.loc[:,'held_time'] = dfBHt['timestamp'].diff().replace(pd.NaT,pd.Timedelta(seconds=1)).dt.total_seconds()/total_seconds\n",
    "    dfBHt.loc[:,'eligible_tvl'] = dfBHt['cumsum'] * dfBHt['held_time']\n",
    "    dfBHt.loc[:,'month'] = dfBHt['timestamp'].dt.to_period('M')\n",
    "    \n",
    "    # Special handling for sUSDS token to convert to USD value\n",
    "    if current_contract == '0xa3931d71877c0e7a3148cb7eb4463524fec27fbd':\n",
    "        testTail = dfBHt['eligible_tvl'].tail().copy()\n",
    "        dfBHt.loc[:,'eligible_tvl'] = dfBHt.apply(lambda x: rowToUSDValue(x), axis=1)\n",
    "\n",
    "    # Aggregate rewards by month\n",
    "    dfReward = (dfBHt.groupby('month')['eligible_tvl'].sum()/1e18).reset_index()\n",
    "    dfReward.loc[:,'contract'] = current_contract\n",
    "    dfReward.loc[:,'ref_code'] = r[1]['ref_code']\n",
    "    \n",
    "    # Combine with overall rewards\n",
    "    if dfRewards is None:\n",
    "        dfRewards = dfReward\n",
    "    else:\n",
    "        dfRewards = pd.concat([dfRewards,dfReward])\n",
    "    dfBHs.append(dfBHt)\n",
    "    slog('___________', current_contract, r[1]['ref_code'], i,'___________')\n",
    "    i+=1\n",
    "\n",
    "# Final reward calculations and cleanup    \n",
    "dfRewards.rename(columns={'ref_code':'referral_code'},inplace=True)\n",
    "dfRewards['eligible_tvl'] = dfRewards['eligible_tvl'].astype(np.float64)\n",
    "dfRAgg = dfRewards.groupby(['month', 'referral_code'])['eligible_tvl'].sum().reset_index()\n",
    "\n",
    "slog(\"Done calculating rewards\", dfRAgg.index)\n",
    "\n",
    "# Calculate final payouts\n",
    "dfRAggPayout = dfRAgg\n",
    "dfRAggPayout['payout'] = dfRAggPayout['eligible_tvl'] * reward_percentage\n",
    "dfRAggPayout\n",
    "\n",
    "# %%\n",
    "# Pot analysis\n",
    "ps = pd.DataFrame(pots)\n",
    "\n",
    "# %%\n",
    "# Calculate total amount in pots\n",
    "dfPots = pd.DataFrame(pots)\n",
    "dfPots['amount'].sum() / 1e18\n",
    "\n",
    "# %%\n",
    "# Helper function to calculate amount changes from events\n",
    "def rowToAmount(row):\n",
    "    if row['event_name'] == 'deposit':\n",
    "        return int(row['dl']['shares'])\n",
    "    elif row['event_name'] == 'withdraw':\n",
    "        return -1*int(row['dl']['shares'])\n",
    "    elif row['event_name'] == 'withdrawn':\n",
    "        return -1*int(row['dl']['amount'])\n",
    "    elif row['event_name'] == 'staked':\n",
    "        return int(row['dl']['amount'])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# %%\n",
    "# Validation function to check contract balances\n",
    "def checkContract(conNum):\n",
    "    dfRelEventsRef[(dfRelEventsRef['contract_address'] ==contracts[conNum])]['event_name'].value_counts()\n",
    "    stakeSum = (dfRelEventsRef[(dfRelEventsRef['event_name'] != 'referral') & (dfRelEventsRef['contract_address'] ==contracts[conNum])  ].apply(lambda x: rowToAmount(x),axis=1).sum() / 1e18)\n",
    "    stakeSum\n",
    "    computed_sum = dfPots[dfPots['contract'] == contracts[conNum]]['amount'].sum() / 1e18\n",
    "    if abs( stakeSum - (computed_sum))>1:\n",
    "        return \" \".join([str(x) for x in ['\\n!!ERROR!!\\n Contract', contracts[conNum], \"stake sum mismatch\",\n",
    "                                        stakeSum, (computed_sum),\n",
    "                                        'OFF BY:', stakeSum - computed_sum,\n",
    "                                        \"=>\", f'{ 100*(abs(stakeSum / computed_sum)-1):3.5f}%']])\n",
    "    else:\n",
    "        return \" \".join([str(x) for x in ['OK!! Contract', contracts[conNum], \"stake sum MATCH\",\n",
    "                                        stakeSum, computed_sum]])\n",
    "\n",
    "# %%\n",
    "# Run validation checks\n",
    "slog('\\n!!SANITY CHECKS!!')\n",
    "logs = []\n",
    "for c in range(len(contracts)):\n",
    "    logs.append(checkContract(c))\n",
    "for l in logs:\n",
    "    slog(l)\n",
    "slog('!!SANITY CHECKS!!\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
